# Automatiser la recherche de mots cles avec une IA

Ce cours présente un script innovant conçu pour simuler l'expérience de recherche Google SGE en fusionnant les capacités des modèles de langage avec les résultats du moteur de recherche traditionnel. L'objectif principal est d'automatiser l'extraction d'entités sémantiques et de mots-clés stratégiques afin d'optimiser le référencement naturel des contenus. Le processus repose sur la génération de multiples requêtes et réponses pour couvrir un sujet en profondeur, permettant ainsi d'identifier les concepts les plus pertinents aux yeux de l'IA et de Google. En synthétisant ces données dans un fichier exploitable, l'outil offre aux créateurs un répertoire de vocabulaire spécifique garantissant une meilleure indexation et une pertinence accrue face aux algorithmes modernes.

Vous êtes arrivé à la moitié de la formation. Les agents, les prépromptes, les technologies Google sont désormais des concepts connus. Je vous propose dans ce cours de découvrir le script qui permet de simuler Google SGE. Et j'ai découpé en plusieurs vidéos pour bien comprendre les usages. Découvrons ensemble le code qui permet donc de simuler Google SGE. Donc l'adresse se trouvera dans les annexes au-dessus de cette vidéo. Alors la phase la plus importante, ça va être de lancer ce setup. Donc vous cliquez ici sur le bouton lecture et limite c'est le seul code que vous allez voir dans cette vidéo parce que quand vous allez installer la librairie Google, vous allez voir, il va vous demander de redémarrer l'instance. Donc il faut cliquer dessus sinon pour la suite vous aurez une erreur. Une fois que c'est fait, donc là c'est sûrement la seule partie qu'il va falloir configurer. Donc mettre votre clé Google mettre l'ID de votre Google Search API, mettre aussi euh une clé d'API pour Open Ei et définir le nom du projet dans Google Cloud et la localisation de ce projet. Alors, je vais juste vous donner une petite astuce pour le trouver très rapidement. Quand ici je reviens dans vertexi, si vous cliquez ici sur view code, il vous donne cette information là. Là, il me dit que mon projet s'appelle data marketing lab. Donc je le voyais déjà ici, mais surtout que le projet est localisé sur US central 1\. Pour la clé d'API Open bon, j'ai déjà fait des vidéos et des formations sur cette plateforme mais tout se trouve ici dans API Key et créer ici une nouvelle clé secrète et venir tout copier dans le notebook. Donc là pour des raisons de sécurité forcément j'ai caché mes clés. Une fois que c'est fait donc vous pouvez vérifier d'abord le fonctionnement de Google Search API. Donc Là par exemple, je fais une recherche aux US sur le mot bike et vous voyez, il me retourne bien pour tout ce qui se trouve dans Google, le titre, le lien, le snipet. Le snipet c'est juste un extrait de chacune de ces URL et qui va nous être très utile euh pour la suite. Ensuite, donc tout le code est caché là avec Palme 2 et Open Yi. Donc on y reviendra plus tard. Comment ça va fonctionner ? Bah tout d'abord, je définis le le nombre de requêtes que je veux simuler et pour chacune de ces requêtes le nombre de générations que je veux faire. Je m'explique. Donc ici par exemple, je vais acheter un un ordinateur rouge à moins de 300 dollars. Voyez, je vais générer les requêtes. Et grosso modo, il m'en propose plusieurs. C'est-à-dire que il me dit que pour ordinateur rouge à 300 dollars, on peut être intéressé partout. Quel est le meilleur ? Ici requête suivante, quelles sont les caractéristiques ? Quels sont les avantages et les inconvénients et cetera ? En effet, pour extraire des informations d'un LLM, vous pouvez pas y aller qu'avec une seule requête. Plus ici vous allez venir gonfler le chiffre, meilleur ça sera. Par contre, faites très attention au coup de génération parce que encore une fois, on aura pas les meilleurs résultats avec une seule réponse. Donc, d'abord, on génère un maximum de requête et pour ces roquette, on fait plusieurs générations. Une fois que c'est fait, là on on peut voir ce qui se passe, c'est que il va s'amuser donc à simuler toutes ses requêtes et à chaque fois venir extraire les on va appeler ça les entités nommées ou les entités remarquables, donc des mots clés qui sont spécifiques à ce texte. Donc là par exemple, vous pouvez voir alors sans surprise euh les tours PC rouges euh cors donc ça c'est c'est de la mémoire, il parle les caractéristiques, une bonne ventilation, rangement de câble et cetera. Et c'est ces concepts là qu'on va venir extraire. Donc forcément, il y en a énormément. Et une fois que c'est fait avec ce code là, donc en plus c'est génial, c'est que si vous cliquez ici, à chaque fois ça va, j'ai fait en sorte que ça extrait les données dans un fichier Excel. Donc ici, vous voyez pour pour chacune des réponses les concepts qu'il a qu'il a extrait et le mieux c'est la dernière analyse. En fait, ça va ça va tout simplement regrouper les les entités communes. Donc ça les analyse une par une et ça les regroupe. Et donc si vous avez bien travaillé, alors voyez ici là, j'affiche en mode tableau. Donc c'est très facile de de trier mais vous voyez toutes les les entités que le LLM connaît. Donc c'est les entités elle est plus fréquente forcément là il y a il y a plus de 11 pages mais si vous utilisez ces entités il y a de grandes chances que comme c'est dans les connaissance du LLM que votre contenu s'indexe beaucoup plus facilement. Encore une fois ça vient pas seulement du LLM. En parallèle on a récupéré les meilleurs résultats sur Google mais ce que j'ai remarqué c'est que cette fusion entre les connaissances du LLM et les meilleurs résultats du Google vous donne les meilleures entités à utiliser pour écrire votre contenu. Donc là, on retrouve vraiment un vocabulaire qui tourne autour de de l'informatique et je vous laisserai explorer et tester sur les les requêtes de votre show. Donc c'est une vidéo assez dense et dans la prochaine, on va commencer à regarder le détail du code.

Core Methodology of the SGE Simulation  
The simulation process follows a specific workflow to extract the most relevant information:

* Multi-Query Generation: To get the best results, the system does not rely on a single request. It generates multiple related queries (e.g., for "red computer under $300," it might ask about characteristics, pros, and cons) and performs several generations for each to ensure comprehensive data extraction.  
* Data Fusion: The process combines the best results from Google Search with the internal knowledge of an LLM. This "fusion" is considered the most effective way to identify the best entities to use when writing content.  
* Entity Extraction: The system identifies named entities or "remarkable entities"—specific keywords and concepts (like "good ventilation" or "cable management" for PCs) that are frequently associated with the topic.

Technical Implementation  
The simulation is typically run in a Google Colab environment and utilizes several APIs and technologies:

* Google Search API: Used to retrieve titles, links, and snippets (brief summaries) from the top search results.  
* LLMs (PaLM 2 & OpenAI): The script uses a mix of models. PaLM 2 (specifically the "Bison" model) is used to generate questions around a subject, while OpenAI (GPT-3.5 Turbo) is often preferred for its performance in extracting specific entities and domain-specific expressions from text.  
* Trafilatura: This tool is used to extract the main content from web pages to feed into the instructions.  
* Parallel Processing: To save time, the script uses threading to execute multiple API calls in parallel, as processing them sequentially would take too long.

Practical Benefits for SEO  
The ultimate goal of simulating SGE is to improve content indexing. By identifying the entities and concepts that the LLM already "knows" and those that appear in top search results, creators can write content that aligns with how search engines understand a topic. The results are often exported to Excel, grouping common entities to help the user identify the most frequent and important terms to include in their writing  
